{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet Sentiment Extraction v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMQxldwIyFqFe/y7Ss003ZE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPDMiQLL4V8o"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "A list of tweets have been classified as either neutral, negative, or positive.  The model predicts selected text in the tweets that determines the classified sentiment.\n",
        "\n",
        "https://www.kaggle.com/c/tweet-sentiment-extraction/overview/evaluation\n",
        "\n",
        "X = text, sentiment\n",
        "\n",
        "y = selected_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr7jZBIx3xRG"
      },
      "source": [
        "# Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1AOJIh25-8P"
      },
      "source": [
        "### Public libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP5hJorF3tRc",
        "outputId": "e99a1733-c085-4172-c408-b0b4be29995a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "# nltk library\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk import classify\n",
        "from nltk import NaiveBayesClassifier\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# keras\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2x11Klr6C3g"
      },
      "source": [
        "### Custom functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hnCJ6nwVRpq"
      },
      "source": [
        "def clean_text(tokenized_sentence):\n",
        "  \"\"\"\n",
        "  Input = list of strings that is tokenized sentence \n",
        "\n",
        "  Return = list of strings that is a lower case tokenized sentence\n",
        "  \"\"\"\n",
        "  lower_case_words = []\n",
        "  for words in tokenized_sentence:\n",
        "    lower_case_words.append(words.lower())\n",
        "\n",
        "  return lower_case_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTd225SEKPRz"
      },
      "source": [
        "### Score function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g0G5Xd3KO0C"
      },
      "source": [
        "# Compares the words between actual and prediction\n",
        "def jaccard(str1, str2): \n",
        "    a = set(str1.lower().split()) \n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "# Same function except for already tokenized text\n",
        "def jaccard_token(str1, str2): \n",
        "    a = set(str1) \n",
        "    b = set(str2)\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LagwUe5V36-Y"
      },
      "source": [
        "# EDA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_ZDDdqp3_3a"
      },
      "source": [
        "### Data Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxFjEMcJ4CHd",
        "outputId": "98581d4c-5645-4008-e6ef-51a9d84d6a73"
      },
      "source": [
        "# Load the dataset\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/sli0111/tweet_sentiment_extraction/main/train.csv')\n",
        "train.head(10)\n",
        "print(train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(27481, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5btv8TFtdBID"
      },
      "source": [
        "Notice that for text that are considered neutral, the selected text is just the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "_D8V95kx5mt6",
        "outputId": "173923bb-0b1c-4514-a959-3e0845564a63"
      },
      "source": [
        "# Check for missing values\n",
        "np.sum(train.isna())\n",
        "\n",
        "train[train['text'].isna()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>fdb77c3752</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         textID text selected_text sentiment\n",
              "314  fdb77c3752  NaN           NaN   neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuzdGO-OE37L",
        "outputId": "e324572c-68b3-4b2d-f79b-a628675ab72b"
      },
      "source": [
        "# Replace row 314 with 0\n",
        "train = train.fillna('0')\n",
        "np.sum(train.isna())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "textID           0\n",
              "text             0\n",
              "selected_text    0\n",
              "sentiment        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo8yV7zS6df1",
        "outputId": "929a5ed0-5e48-47a1-8b9e-68c4744290ba"
      },
      "source": [
        "# All text objects\n",
        "train.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "textID           object\n",
              "text             object\n",
              "selected_text    object\n",
              "sentiment        object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bywlld-B7ezs",
        "outputId": "b9c1dc49-3409-45e3-b4e6-fc79fa4d1c27"
      },
      "source": [
        "# Total unique IDs match total rows\n",
        "train.shape[0] == np.sum(np.unique(train['textID'], return_counts=True)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLVC_4Ra8FnR"
      },
      "source": [
        "Overall the data is clean.  Each row is a unique ID.  Removed one missing row of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94z8bPF47Wbl"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Kcq-oXKS8FG7",
        "outputId": "3fb5ce1c-5808-44c6-b060-339028a2d680"
      },
      "source": [
        "# Distribution of sentiment - a lot of neutrals\n",
        "sns.histplot(y='sentiment', data=train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbfc834bcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRp9znf8c2KW"
      },
      "source": [
        "The figure above shows the that majority of the text are considered netural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOFRtYcG9XM6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "232a3e0b-5a6b-4c3a-bc0c-2d6f90197f34"
      },
      "source": [
        "# Convert the selected_text to word tokens\n",
        "word_tokens = [word_tokenize(str(i)) for i in train['selected_text']]\n",
        "clean_tokens = [clean_text(i) for i in word_tokens]\n",
        "train['selected_text_tokens'] = clean_tokens\n",
        "\n",
        "# Convert the text to word tokens\n",
        "word_tokens = [word_tokenize(str(i)) for i in train['text']]\n",
        "clean_tokens = [clean_text(i) for i in word_tokens]\n",
        "train['text_tokens'] = clean_tokens\n",
        "\n",
        "train.head(5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>selected_text_tokens</th>\n",
              "      <th>text_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[i`d, have, responded, ,, if, i, were, going]</td>\n",
              "      <td>[i`d, have, responded, ,, if, i, were, going]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>[sooo, sad]</td>\n",
              "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>[bullying, me]</td>\n",
              "      <td>[my, boss, is, bullying, me, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>[leave, me, alone]</td>\n",
              "      <td>[what, interview, !, leave, me, alone]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>[sons, of, ****, ,]</td>\n",
              "      <td>[sons, of, ****, ,, why, couldn`t, they, put, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID  ...                                        text_tokens\n",
              "0  cb774db0d1  ...      [i`d, have, responded, ,, if, i, were, going]\n",
              "1  549e992a42  ...  [sooo, sad, i, will, miss, you, here, in, san,...\n",
              "2  088c60f138  ...                  [my, boss, is, bullying, me, ...]\n",
              "3  9642c003ef  ...             [what, interview, !, leave, me, alone]\n",
              "4  358bd9e861  ...  [sons, of, ****, ,, why, couldn`t, they, put, ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTAbknWDkDYf",
        "outputId": "d17ba601-8f70-4991-9ad9-db5169bfa235"
      },
      "source": [
        "def get_all_words(tokens_list):\n",
        "  for tokens in tokens_list:\n",
        "    for token in tokens:\n",
        "      yield token\n",
        "\n",
        "pos_train = train[train['sentiment'] == 'positive']\n",
        "neg_train = train[train['sentiment'] == 'negative']\n",
        "\n",
        "all_pos_words = get_all_words(pos_train['text_tokens'])\n",
        "all_neg_words = get_all_words(neg_train['text_tokens'])\n",
        "\n",
        "print(FreqDist(all_pos_words).most_common(10))\n",
        "print(FreqDist(all_neg_words).most_common(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('!', 6629), ('.', 4440), ('i', 3773), ('the', 2996), ('to', 2975), (',', 2812), ('a', 2385), ('you', 2075), ('and', 1678), ('my', 1485)]\n",
            "[('i', 4586), ('.', 4580), ('!', 3918), ('to', 2893), ('the', 2454), (',', 2319), ('my', 2035), ('a', 1807), ('...', 1707), ('and', 1579)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI90AxgIZjJe"
      },
      "source": [
        "# Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXXBbjaAZq_U"
      },
      "source": [
        "A Naive Bayes Classifier will be used as a first model below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxtcDn_BZopB"
      },
      "source": [
        "### Create dictionaries for each tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKRfm_kKqZpF"
      },
      "source": [
        "# Returns a generative object of dictionaries\n",
        "# Tags True for the sentiment the text belongs to\n",
        "def get_tweets_for_model(cleaned_tokens_list):\n",
        "  for tweet_tokens in cleaned_tokens_list:\n",
        "    yield dict([token, True] for token in tweet_tokens)\n",
        "                                                 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr9tKEVG_YXb",
        "outputId": "10ea0527-834f-4dc1-f292-f1c5fab2bd1c"
      },
      "source": [
        "# Add the dictionaries to the train dataframe to ease of visualization\n",
        "train['tokens_for_model'] = [(tweet_dict, train['sentiment'][i]) \n",
        "                              for i, tweet_dict in enumerate(get_tweets_for_model(train['text_tokens']))]\n",
        "train['tokens_for_model']\n",
        "                            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        ({'i`d': True, 'have': True, 'responded': True...\n",
              "1        ({'sooo': True, 'sad': True, 'i': True, 'will'...\n",
              "2        ({'my': True, 'boss': True, 'is': True, 'bully...\n",
              "3        ({'what': True, 'interview': True, '!': True, ...\n",
              "4        ({'sons': True, 'of': True, '****': True, ',':...\n",
              "                               ...                        \n",
              "27476    ({'wish': True, 'we': True, 'could': True, 'co...\n",
              "27477    ({'i`ve': True, 'wondered': True, 'about': Tru...\n",
              "27478    ({'yay': True, 'good': True, 'for': True, 'bot...\n",
              "27479    ({'but': True, 'it': True, 'was': True, 'worth...\n",
              "27480    ({'all': True, 'this': True, 'flirting': True,...\n",
              "Name: tokens_for_model, Length: 27481, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDKI62B6sxAo"
      },
      "source": [
        "### Split Train Dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXapD94-sDPs"
      },
      "source": [
        "# Ignore the neutral values\n",
        "train_data = train[train['sentiment'] != 'neutral'][:13000]\n",
        "dev_data = train[train['sentiment'] != 'neutral'][13000:]\n",
        "\n",
        "# Split to train\n",
        "X_train = list(train_data['tokens_for_model'])\n",
        "sentiment_train = list(train_data['sentiment'])\n",
        "y_train = list(train_data['selected_text'])\n",
        "y_train_tokens = list(train_data['selected_text_tokens'])\n",
        "\n",
        "# Split to dev\n",
        "X_dev = list(dev_data['tokens_for_model'])\n",
        "sentiment_dev = list(dev_data['sentiment'])\n",
        "y_dev = list(dev_data['selected_text'])\n",
        "y_dev_tokens = list(dev_data['selected_text_tokens'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hUW5dMXJNOg"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkCOAchWMKNt",
        "outputId": "9692b88c-cabd-4804-8638-2e109ec98c27"
      },
      "source": [
        "# Naive Bayes Classifier\n",
        "classifier = NaiveBayesClassifier.train(X_train)\n",
        "print(\"Accuracy is:\", classify.accuracy(classifier, X_dev))\n",
        "\n",
        "print(classifier.show_most_informative_features())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is: 0.8650014867677669\n",
            "Most Informative Features\n",
            "                mother`s = True           positi : negati =     91.2 : 1.0\n",
            "                   sucks = True           negati : positi =     61.6 : 1.0\n",
            "                   thank = True           positi : negati =     50.4 : 1.0\n",
            "                     sad = True           negati : positi =     50.3 : 1.0\n",
            "                    hate = True           negati : positi =     48.9 : 1.0\n",
            "                   bored = True           negati : positi =     43.3 : 1.0\n",
            "                 welcome = True           positi : negati =     43.1 : 1.0\n",
            "                    moms = True           positi : negati =     38.4 : 1.0\n",
            "                 awesome = True           positi : negati =     36.1 : 1.0\n",
            "                   hurts = True           negati : positi =     33.8 : 1.0\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "054BHDbP5di9"
      },
      "source": [
        "# Returns the tokens and/or index with highest probability in each sentiment\n",
        "def high_word_sentiment(sent_dict, label, threshold):\n",
        "  top_values = [] \n",
        "  index = []  \n",
        "  i = 0\n",
        "  for key, value in sent_dict.items():\n",
        "    word_dict = {key: value}\n",
        "    dist = classifier.prob_classify(word_dict)\n",
        "    if dist.prob(label) > threshold:\n",
        "      top_values.append(key)\n",
        "      index.append(i)\n",
        "    i += 1\n",
        "  return top_values, index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lPgHjfR87Cl"
      },
      "source": [
        "# Returns the prediction of the data based on threshold probability t\n",
        "def baseline_predictions(data, t):\n",
        "  predictions = []\n",
        "  for i in range(len(data)):\n",
        "    guess_word, guess_index = high_word_sentiment(data[i][0], data[i][1], threshold=t)\n",
        "    predictions.append(guess_word)\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB4sH5Q_PTh4",
        "outputId": "2fd5df07-02a3-414b-d38e-1f0222e77739"
      },
      "source": [
        "# Sample predictions\n",
        "baseline_predictions_train = baseline_predictions(X_train, t=0.7)\n",
        "baseline_predictions_dev = baseline_predictions(X_dev, t=0.7)\n",
        "\n",
        "baseline_predictions_train[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['sad', 'miss', 'diego'],\n",
              " ['bullying'],\n",
              " [],\n",
              " ['****', 'why', 'couldn`t'],\n",
              " ['feedings', 'fun', 'smiles', 'coos'],\n",
              " ['journey', 'wow', 'became', 'cooler', 'hehe'],\n",
              " ['song', 'love', 'taylor', 'swift'],\n",
              " ['sharpie', 'dangerously', 'ink'],\n",
              " ['lost'],\n",
              " ['sunburned']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kofMovhmQbjq",
        "outputId": "43c09de1-f3c9-4420-bee5-c2fbac4de946"
      },
      "source": [
        "# Relative to actual\n",
        "y_train_tokens[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['sooo', 'sad'],\n",
              " ['bullying', 'me'],\n",
              " ['leave', 'me', 'alone'],\n",
              " ['sons', 'of', '****', ','],\n",
              " ['fun'],\n",
              " ['wow', '...', 'u', 'just', 'became', 'cooler', '.'],\n",
              " ['like'],\n",
              " ['dangerously'],\n",
              " ['lost'],\n",
              " ['uh', 'oh', ',', 'i', 'am', 'sunburned']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxfF4ZiPbKZA"
      },
      "source": [
        "### Model Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EOq6bk4XRl3",
        "outputId": "e298f74d-6b8b-4b2d-c92a-32df992bc1ca"
      },
      "source": [
        "# Jaccuard token score for several thresholds\n",
        "t_values = np.linspace(0.1, 0.9, 5)\n",
        "for t in t_values:\n",
        "  baseline_predictions_train = baseline_predictions(X_train, t=t)\n",
        "\n",
        "  scores = []\n",
        "  num_examples = len(baseline_predictions_train)\n",
        "  for i in range(num_examples):\n",
        "    scores.append(jaccard_token(baseline_predictions_train[i], y_train_tokens[i]))\n",
        "\n",
        "  avg_score = np.sum(scores)/num_examples\n",
        "  print(round(avg_score, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.332\n",
            "0.329\n",
            "0.297\n",
            "0.285\n",
            "0.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfc2F5qZg5cG",
        "outputId": "f7d62b20-e398-4379-f491-9e7769e51810"
      },
      "source": [
        "# Similarty for dev\n",
        "t_values = np.linspace(0.1, 0.9, 5)\n",
        "for t in t_values:\n",
        "  baseline_predictions_train = baseline_predictions(X_dev, t=t)\n",
        "\n",
        "  scores = []\n",
        "  num_examples = len(baseline_predictions_dev)\n",
        "  for i in range(num_examples):\n",
        "    scores.append(jaccard_token(baseline_predictions_dev[i], y_dev_tokens[i]))\n",
        "\n",
        "  avg_score = np.sum(scores)/num_examples\n",
        "  print(round(avg_score, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3\n",
            "0.3\n",
            "0.3\n",
            "0.3\n",
            "0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGpJnQawbNof"
      },
      "source": [
        "# Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvtN6x6fWsSK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5KM40liJgqM"
      },
      "source": [
        "# References\n",
        "\n",
        "https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk"
      ]
    }
  ]
}